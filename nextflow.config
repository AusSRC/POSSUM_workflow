profiles {
    setonix {
        process {
            executor = 'local'
            module = ['singularity/3.11.4-slurm']
            clusterOptions = "--account=ja3 --time=24:00:00"

            beforeScript = """. /opt/cray/pe/lmod/lmod/init/bash"""

            withName: file_complete_csv {
                executor = 'local'
                module = ['python/3.10.10']
            }

            withName: pull_racstools_image {
                executor = 'slurm'
                queue = 'work'
                clusterOptions = '--mem-per-cpu=32G --time=24:00:00'
            }

            withName: download {
                executor = 'slurm'
                queue = 'copy'
                clusterOptions = '--account=ja3 --time=24:00:00'
            }

            withName: frion_predict {
                executor = 'slurm'
                queue = 'work'
                clusterOptions = '--account=ja3 --ntasks=1 --nodes=1 --ntasks-per-node=1 --mem-per-cpu=128G --exclusive --time=24:00:00'
            }

            withName: frion_correct {
                executor = 'slurm'
                queue = 'work'
                clusterOptions = '--account=ja3 --ntasks=1 --nodes=1 --ntasks-per-node=1 --mem-per-cpu=128G --exclusive --time=24:00:00'
            }

            withName: beamcon_3D {
                module = ['singularity/3.11.4-mpi']
                executor = 'slurm'
                queue = 'work'
                clusterOptions = '--account=ja3 --ntasks=36 --nodes=8 --ntasks-per-node=6 --mem-per-cpu=32G --exclusive --time=24:00:00'
            }

            withName: beamcon_2D {
                module = ['singularity/3.11.4-slurm']
                executor = 'slurm'
                queue = 'work'
                clusterOptions = '--account=ja3 --mem-per-cpu=32G --exclusive --time=24:00:00'
            }

            withName: run_hpx_tiling {
                executor = 'slurm'
                queue = 'work'
                clusterOptions = '--account=ja3 --ntasks=1 --nodes=1 --ntasks-per-node=1 --mem-per-cpu=48G --exclusive --time=24:00:00'
            }

            withName: join_split_hpx_tiles {
                executor = 'slurm'
                queue = 'work'
                clusterOptions = '--account=ja3 --ntasks=1 --nodes=1 --ntasks-per-node=1 --mem-per-cpu=64G --exclusive --time=24:00:00'
            }

            withName: repair_tiles {
                executor = 'slurm'
                queue = 'work'
                clusterOptions = '--account=ja3 --ntasks=1 --nodes=1 --ntasks-per-node=1 --mem-per-cpu=32G --exclusive --time=24:00:00'
            }

            withName: run_linmos {
                executor = 'slurm'
                queue = 'work'
                module = ['singularity/3.11.4-mpi']
                clusterOptions = '--mem-per-cpu=32G --account=ja3 --exclusive --time=24:00:00'
            }

            withName: run_linmos_mpi {
                executor = 'slurm'
                queue = 'work'
                module = ['singularity/3.11.4-mpi']
                clusterOptions = '--nodes=1 --ntasks-per-node=6 --mem-per-cpu=32G --account=ja3 --exclusive --time=24:00:00'
            }

            withName: objectstore_upload_component {
                executor = 'slurm'
                queue = 'copy'
                module = ['rclone/1.62.2']
                clusterOptions = '--account=ja3 --time=24:00:00'
            }

            withName: objectstore_download_component {
                executor = 'slurm'
                queue = 'copy'
                module = ['rclone/1.62.2']
                clusterOptions = '--account=ja3 --time=24:00:00'
            }

            withName: objectstore_upload_pixel {
                executor = 'slurm'
                queue = 'copy'
                module = ['rclone/1.62.2']
                clusterOptions = '--account=ja3 --time=24:00:00'
            }

	    withName: objectstore_upload_stokes_component {
                executor = 'slurm'
                queue = 'copy'
                module = ['rclone/1.62.2']
                clusterOptions = '--account=ja3 --time=24:00:00'
            }
        }

        env {
            XDG_CACHE_HOME = "/scratch/ja3/dpallot/"
        }

        params {
            SCRATCH_ROOT = "/scratch"
            WORKDIR = "/scratch/ja3/possum_survey/survey"
            CASADATA = "/scratch/ja3/possum_survey/conf"

            CASDA_CREDENTIALS = "/scratch/ja3/possum_survey/conf/casda.ini"
            HPX_TILE_CONFIG = "/scratch/ja3/possum_survey/conf/hpx_tile_config.json"
            HPX_TILE_TEMPLATE = "/scratch/ja3/possum_survey/conf/tile-template.fits"

            SINGULARITY_CACHEDIR = "/scratch/ja3/possum_survey/images"
            SINGULARITY_TMPDIR = "/scratch/ja3/possum_survey/images/tmp"
            NUMBA_CACHE_DIR = "/scratch/ja3/possum_survey/conf/numba"
        }

        workDir = "/scratch/ja3/possum_survey/work"
        tmpDir = "/scratch/ja3/possum_survey/tmp"

        singularity {
            enabled = true
            envWhitelist = 'SINGULARITY_BINDPATH, SINGULARITYENV_LD_LIBRARY_PATH, SINGULARITYENV_LD_PRELOAD'
            cacheDir = "/scratch/ja3/possum_survey/images"
            runOptions = "--rocm"
        }

        docker.enabled = false
    }

    carnaby {
        process {
            executor = 'local'
            module = ['singularity']
            clusterOptions = "--time=24:00:00"

            withName: file_complete_csv {
                executor = 'local'
                module = ['wallaby-python']
            }

            withName: run_linmos {
                executor = 'slurm'
            }

            withName: run_linmos_mpi {
                executor = 'slurm'
                queue = 'cpu'
                clusterOptions = '--nodes=1 --ntasks-per-node=6'
            }
        }

        env {
            RCLONE_CONFIG = "/mnt/shared/home/ashen/.config/rclone/possum.conf"
        }

        params {
            SCRATCH_ROOT = "/mnt/shared"
            WORKDIR = "/mnt/shared/possum/survey"
            CASADATA = "/mnt/shared/possum/config"

            CASDA_CREDENTIALS = "/mnt/shared/home/ashen/possum/config/casda.ini"
            HPX_TILE_CONFIG = "/mnt/shared/home/ashen/possum/config/hpx_tile_config.json"
            HPX_TILE_TEMPLATE = "/mnt/shared/home/ashen/possum/config/tile-template.fits"

	    NUMBA_CACHE_DIR = "/mnt/shared/possum/config/numba"
            SINGULARITY_CACHEDIR = "/mnt/shared/possum/apps/singularity"
            SINGULARITY_TMPDIR = "/mnt/shared/possum/apps/singularity/tmp"
        }

        workDir = "/mnt/shared/possum/work"
        tmpDir = "/mnt/shared/possum/tmp"

        singularity {
            enabled = true
            envWhitelist = 'SINGULARITY_BINDPATH, SINGULARITYENV_LD_LIBRARY_PATH, SINGULARITYENV_LD_PRELOAD'
            cacheDir = "/mnt/shared/possum/images"
        }
    }
}

params {
    SURVEY_COMPONENT = "survey"

    BEAMCON_2D_SUFFIX = "sm"
    BEAMCON_3D_SUFFIX = "total"
    BMAJ = 20
    BMIN = 20
    BPA = 0
    CUTOFF = 20
    ZERO_SPLIT_CUBE_SUBDIR = "nan_to_zero"
    NSPLIT = 8
    NAN_TO_ZERO_NSPLIT = 8

    FRION_PREDICT_OUTFILE = "frion_predict.txt"
    FRION_Q_CUBE_FILENAME = "q.fits"
    FRION_U_CUBE_FILENAME = "u.fits"

    HPX_TILE_PREFIX = "PSM"
    SPLIT_CUBE_SUBDIR = "split"
    EVALUATION_FILES_DIR = "evaluation_files"
    TILE_COMPONENT_OUTPUT_DIR = "components"

    LINMOS_IMAGE = "csirocass/askapsoft:1.14.0-setonix"
    LINMOS_IMAGE_NAME = "askapsoft"
    RACS_TOOLS_IMAGE = "docker://alecthomson/racstools:latest"
    MONTAGE_IMAGE = "docker://astroaustin/montage:latest"
    IONOSPHERIC_CORRECTION_IMAGE = "docker://aussrc/frion:latest"
    METADATA_IMAGE = "docker://aussrc/metadata_tools:latest"
    HPX_TILING_IMAGE = "docker://aussrc/hpx_tiles:latest"
    MOSAICKING_COMPONENTS_IMAGE = "docker://aussrc/mosaicking_tools:latest"
    CASDA_DOWNLOAD_IMAGE = "docker://aussrc/casda_download:latest"
}
